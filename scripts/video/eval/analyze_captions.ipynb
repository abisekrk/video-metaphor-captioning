{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/research/video_metaphor/LLaVA/results/llava13-b/vmcd_ispy/24f_4parts/5_ep/answers_t_0_2_test.jsonl\", \"r\")\n",
    "questions = [json.loads(q) for q in file]\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 0,\n",
       " 'prompt': 'What metaphor can best describe the video?',\n",
       " 'video_id': 'jmNrvlQ73pU',\n",
       " 'true_caption': 'the burger is as comforting as relationship',\n",
       " 'text': 'the toys are as cute as the girl.',\n",
       " 'answer_id': 'WpKhrFYFcFVNBv3gLmomGE',\n",
       " 'model_id': 'llava1.5-13b-24f-4part_checkpoint-375',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[0]\n",
    "# true_captions = [ q[\"true_caption\"].split(\":\")[1].strip() for q in questions]\n",
    "true_captions = [ q[\"true_caption\"] for q in questions]\n",
    "pred_captions = [ q[\"text\"].split(\"\\n\")[0] for q in questions]\n",
    "video_ids = [ q[\"video_id\"] for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jmNrvlQ73pU'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>true_caption</th>\n",
       "      <th>pred_captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jmNrvlQ73pU</td>\n",
       "      <td>the burger is as comforting as relationship</td>\n",
       "      <td>the toys are as cute as the girl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jmNrvlQ73pU</td>\n",
       "      <td>a burger is as much a source of satisfaction a...</td>\n",
       "      <td>the toy is as cute as the girl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jmNrvlQ73pU</td>\n",
       "      <td>the burger is as a bond as kids relationship</td>\n",
       "      <td>the chocolate is as sweet as the relationship ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D93S3UVU8pk</td>\n",
       "      <td>the game is as fun as the cartoon</td>\n",
       "      <td>the drink is as cool as a polar bear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D93S3UVU8pk</td>\n",
       "      <td>the game is as interesting as a cartoon.</td>\n",
       "      <td>the game is as exciting as a superhero.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       true_caption  \\\n",
       "0  jmNrvlQ73pU        the burger is as comforting as relationship   \n",
       "1  jmNrvlQ73pU  a burger is as much a source of satisfaction a...   \n",
       "2  jmNrvlQ73pU       the burger is as a bond as kids relationship   \n",
       "3  D93S3UVU8pk                  the game is as fun as the cartoon   \n",
       "4  D93S3UVU8pk           the game is as interesting as a cartoon.   \n",
       "\n",
       "                                       pred_captions  \n",
       "0                  the toys are as cute as the girl.  \n",
       "1                    the toy is as cute as the girl.  \n",
       "2  the chocolate is as sweet as the relationship ...  \n",
       "3              the drink is as cool as a polar bear.  \n",
       "4            the game is as exciting as a superhero.  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame({\"video_id\": video_ids, \"true_caption\":true_captions, \"pred_captions\": pred_captions})\n",
    "print(len(predicted_df))\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>reference_captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-U4Yr9UNBo</td>\n",
       "      <td>[the enormous phone is as good as the minor ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0B79RkBxSgU</td>\n",
       "      <td>[the actor is not as refreshing as a soft drin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0XSNrKgA94g</td>\n",
       "      <td>[chocolate is as light as a man who can fly., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0cP-qr1JUBI</td>\n",
       "      <td>[choosing real estate agent is as important as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10okyjMjlH8</td>\n",
       "      <td>[the game is as flexible as a world with creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>z1zeaOK2atg</td>\n",
       "      <td>[soap is as beautiful as diversity., soap is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>z62vD5BDDUE</td>\n",
       "      <td>[a mutual fund is as visionary as teaching a k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>zKQbsrRutvE</td>\n",
       "      <td>[the burger is as original as irish people, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>zSM6sAtyvyg</td>\n",
       "      <td>[sippy cups are as cool as husbands., sippy cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>z_Wah7jp0Jw</td>\n",
       "      <td>[shared experiences are as sensitive as emotio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                 reference_captions\n",
       "0    0-U4Yr9UNBo  [the enormous phone is as good as the minor ph...\n",
       "1    0B79RkBxSgU  [the actor is not as refreshing as a soft drin...\n",
       "2    0XSNrKgA94g  [chocolate is as light as a man who can fly., ...\n",
       "3    0cP-qr1JUBI  [choosing real estate agent is as important as...\n",
       "4    10okyjMjlH8  [the game is as flexible as a world with creat...\n",
       "..           ...                                                ...\n",
       "245  z1zeaOK2atg  [soap is as beautiful as diversity., soap is a...\n",
       "246  z62vD5BDDUE  [a mutual fund is as visionary as teaching a k...\n",
       "247  zKQbsrRutvE  [the burger is as original as irish people, th...\n",
       "248  zSM6sAtyvyg  [sippy cups are as cool as husbands., sippy cu...\n",
       "249  z_Wah7jp0Jw  [shared experiences are as sensitive as emotio...\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cap_list = {}\n",
    "reference_df = predicted_df.groupby('video_id')['true_caption'].apply(list).reset_index(name=\"reference_captions\")\n",
    "reference_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>true_caption</th>\n",
       "      <th>pred_captions</th>\n",
       "      <th>reference_captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jmNrvlQ73pU</td>\n",
       "      <td>the burger is as comforting as relationship</td>\n",
       "      <td>the toys are as cute as the girl.</td>\n",
       "      <td>[the burger is as comforting as relationship, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jmNrvlQ73pU</td>\n",
       "      <td>a burger is as much a source of satisfaction a...</td>\n",
       "      <td>the toy is as cute as the girl.</td>\n",
       "      <td>[the burger is as comforting as relationship, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jmNrvlQ73pU</td>\n",
       "      <td>the burger is as a bond as kids relationship</td>\n",
       "      <td>the chocolate is as sweet as the relationship ...</td>\n",
       "      <td>[the burger is as comforting as relationship, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D93S3UVU8pk</td>\n",
       "      <td>the game is as fun as the cartoon</td>\n",
       "      <td>the drink is as cool as a polar bear.</td>\n",
       "      <td>[the game is as fun as the cartoon, the game i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D93S3UVU8pk</td>\n",
       "      <td>the game is as interesting as a cartoon.</td>\n",
       "      <td>the game is as exciting as a superhero.</td>\n",
       "      <td>[the game is as fun as the cartoon, the game i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       true_caption  \\\n",
       "0  jmNrvlQ73pU        the burger is as comforting as relationship   \n",
       "1  jmNrvlQ73pU  a burger is as much a source of satisfaction a...   \n",
       "2  jmNrvlQ73pU       the burger is as a bond as kids relationship   \n",
       "3  D93S3UVU8pk                  the game is as fun as the cartoon   \n",
       "4  D93S3UVU8pk           the game is as interesting as a cartoon.   \n",
       "\n",
       "                                       pred_captions  \\\n",
       "0                  the toys are as cute as the girl.   \n",
       "1                    the toy is as cute as the girl.   \n",
       "2  the chocolate is as sweet as the relationship ...   \n",
       "3              the drink is as cool as a polar bear.   \n",
       "4            the game is as exciting as a superhero.   \n",
       "\n",
       "                                  reference_captions  \n",
       "0  [the burger is as comforting as relationship, ...  \n",
       "1  [the burger is as comforting as relationship, ...  \n",
       "2  [the burger is as comforting as relationship, ...  \n",
       "3  [the game is as fun as the cartoon, the game i...  \n",
       "4  [the game is as fun as the cartoon, the game i...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(predicted_df, reference_df, on=['video_id'])\n",
    "print(len(merged_df))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the burger is as comforting as relationship',\n",
       " 'a burger is as much a source of satisfaction as a relationship.',\n",
       " 'the burger is as a bond as kids relationship']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_captions = merged_df[\"reference_captions\"].tolist()\n",
    "reference_captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.translate.bleu_score import corpus_bleu\n",
    "# # references = [[cap.split()] for cap in true_captions]\n",
    "# references = [[cap.split() for cap in references] for references in reference_captions]\n",
    "# candidates = [cap.split() for cap in pred_captions]\n",
    "# score = corpus_bleu(references, candidates, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "# print(score)\n",
    "# score = corpus_bleu(references, candidates, weights=(1, 0,0,0))\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from rouge_score import rouge_scorer\n",
    "\n",
    "# # scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "# # scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "# #                       'The quick brown dog jumps on the log.')\n",
    "\n",
    "# import evaluate\n",
    "# rouge = evaluate.load('rouge')\n",
    "\n",
    "# true_captions_r = [[c] for c in true_captions]\n",
    "# results = rouge.compute(predictions=pred_captions, references=true_captions_r)\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', device=\"cuda\")\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=\"cuda:4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def compute_similarity_between_parts(sentence, f1_score):\n",
    "    pattern = r'as \\w+ as'\n",
    "    parts = re.split(pattern, sentence)\n",
    "\n",
    "    # Remove any leading or trailing whitespace from the parts\n",
    "    parts = [part.strip() for part in parts if part.strip()]\n",
    "    \n",
    "    \n",
    "    if len(parts) < 2:\n",
    "        cosine_score = float(1.0)\n",
    "\n",
    "    else:\n",
    "\n",
    "    #Compute embedding for both primary and secondary concept\n",
    "        # Removing last word from primary concept as it could be is or are\n",
    "        parts[0] = \" \".join(parts[0].split()[:-1])\n",
    "        embeddings1 = model.encode(parts[0], convert_to_tensor=True)\n",
    "        embeddings2 = model.encode(parts[1], convert_to_tensor=True)\n",
    "\n",
    "        #Compute cosine-similarities\n",
    "        cosine_score = util.cos_sim(embeddings1, embeddings2)[0][0]\n",
    "\n",
    "    cosine_distance = 1 - cosine_score\n",
    "    return (cosine_distance * f1_score)\n",
    "\n",
    "def compute_similarity_between_parts_without_f1(sentence):\n",
    "    pattern = r'as \\w+ as'\n",
    "    parts = re.split(pattern, sentence)\n",
    "\n",
    "    # Remove any leading or trailing whitespace from the parts\n",
    "    parts = [part.strip() for part in parts if part.strip()]\n",
    "    \n",
    "    if len(parts) < 2:\n",
    "        # cosine_score = float(1.0)\n",
    "        return float(1.0)\n",
    "\n",
    "    else:\n",
    "\n",
    "    #Compute embedding for both primary and secondary concept\n",
    "        # Removing last word from primary concept as it could be is or are\n",
    "        parts[0] = \" \".join(parts[0].split()[:-1])\n",
    "\n",
    "        embeddings1 = model.encode(parts[0], convert_to_tensor=True)\n",
    "        embeddings2 = model.encode(parts[1], convert_to_tensor=True)\n",
    "\n",
    "        #Compute cosine-similarities\n",
    "        cosine_score = util.cos_sim(embeddings1, embeddings2)[0][0]\n",
    "\n",
    "        return cosine_score\n",
    "\n",
    "    \n",
    "\n",
    "def split_to_parts(sentence):\n",
    "    pattern = r'as \\w+ as'\n",
    "    parts = re.split(pattern, sentence)\n",
    "\n",
    "    # Remove any leading or trailing whitespace from the parts\n",
    "    parts = [part.strip() for part in parts if part.strip()]\n",
    "    # Removing last word from primary concept as it could be is or are\n",
    "    parts[0] = \" \".join(parts[0].split()[:-1])\n",
    "    if len(parts) == 1:\n",
    "        parts.append(\"\")\n",
    "    return parts\n",
    "\n",
    "\n",
    "def compute_similarity(true_caption, predicted_caption):\n",
    "    \n",
    "    #Compute embedding for both primary and secondary concept\n",
    "    embeddings1 = model.encode(true_caption, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(predicted_caption, convert_to_tensor=True)\n",
    "\n",
    "    #Compute cosine-similarities\n",
    "    cosine_score = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "    return float(cosine_score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocoevalcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Maluuba/nlg-eval.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nlgeval.pycocoevalcap.bleu.bleu import Bleu\n",
    "# from nlgeval.pycocoevalcap.rouge.rouge import Rouge\n",
    "# from nlgeval.pycocoevalcap.cider.cider import Cider\n",
    "# from nlgeval.pycocoevalcap.meteor.meteor import Meteor\n",
    "\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.meteor.meteor import Meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(ref, hypo):\n",
    "    scorers = [\n",
    "        (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "        (Rouge(), \"ROUGE_L\"),\n",
    "        (Cider(), \"CIDEr\")\n",
    "    ]\n",
    "    final_scores = {}\n",
    "    all_scores = {}\n",
    "    for scorer, method in scorers:\n",
    "        score, scores = scorer.compute_score(ref, hypo)\n",
    "\n",
    "        if type(score) == list:\n",
    "            for m, s in zip(method, score):\n",
    "                final_scores[m] = s\n",
    "            for m, s in zip(method, scores):\n",
    "                all_scores[m] = s\n",
    "        else:\n",
    "            final_scores[method] = score\n",
    "            all_scores[method] = scores\n",
    "\n",
    "    return final_scores, all_scores\n",
    "\n",
    "\n",
    "def compute(ref, cand, get_scores=True):\n",
    "    # make dictionary\n",
    "    hypo = {}\n",
    "    for i, caption in enumerate(cand):\n",
    "        hypo[i] = [caption]\n",
    "    truth = {}\n",
    "    # for i, caption in enumerate(ref):\n",
    "    #     truth[i] = [caption]\n",
    "    for i, caption in enumerate(ref):\n",
    "        truth[i] = caption\n",
    "\n",
    "    # compute bleu score\n",
    "    final_scores = score(truth, hypo)\n",
    "\n",
    "    #     print out scores\n",
    "    print('Bleu_1:\\t ;', final_scores[0]['Bleu_1']*100)\n",
    "    print('Bleu_2:\\t ;', final_scores[0]['Bleu_2']*100)\n",
    "    print('Bleu_3:\\t ;', final_scores[0]['Bleu_3']*100)\n",
    "    print('Bleu_4:\\t ;', final_scores[0]['Bleu_4']*100)\n",
    "    print('ROUGE_L: ;', final_scores[0]['ROUGE_L']*100)\n",
    "    print('CIDEr:\\t ;', final_scores[0]['CIDEr']*100)\n",
    "\n",
    "    if get_scores:\n",
    "        return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 6223, 'reflen': 6140, 'guess': [6223, 5473, 4723, 3973], 'correct': [3404, 1386, 364, 165]}\n",
      "ratio: 1.013517915309281\n",
      "Bleu_1:\t ; 54.700305318969185\n",
      "Bleu_2:\t ; 37.21891995226695\n",
      "Bleu_3:\t ; 22.019307522630893\n",
      "Bleu_4:\t ; 14.510891253059183\n",
      "ROUGE_L: ; 50.59025726463086\n",
      "CIDEr:\t ; 22.66865495813586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# res = compute(true_captions, pred_captions, get_scores=True)\n",
    "res = compute(reference_captions, pred_captions, get_scores=True)\n",
    "\n",
    "# output = score(true_captions, pred_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = [\"I met batman\", \"I am superman\"]\n",
    "pc = [\"I am batman\", \"I met superman\"]\n",
    "res = compute(tc, pc, get_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7535977378686269\n",
      "0.7252129632631937\n",
      "0.7356398804187775\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "# predictions = [\"hello world\", \"general kenobi\"]\n",
    "# references = [\"hello world\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=pred_captions, references=reference_captions, model_type=\"microsoft/deberta-xlarge-mnli\", device=\"cuda:4\")\n",
    "# results = bertscore.compute(predictions=pred_captions, references=true_captions, lang=\"en\")\n",
    "# print(results)\n",
    "precision = sum(results['precision'])/len(results['precision'])\n",
    "recall = sum(results['recall'])/len(results['recall'])\n",
    "f1 = sum(results['f1'])/len(results['f1'])\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary_secondary_concepts = [split_to_parts(sent) for sent in tqdm(pred_captions)]\n",
    "# # print(primary_secondary_concepts[0:5])\n",
    "\n",
    "# primary_concepts = [item[0] for item in primary_secondary_concepts]\n",
    "# secondary_concepts = [item[1] for item in primary_secondary_concepts]\n",
    "\n",
    "# # print(primary_concepts[0:5])\n",
    "# # print(secondary_concepts[0:5])\n",
    "\n",
    "# results = bertscore.compute(predictions=secondary_concepts, references=primary_concepts, model_type=\"microsoft/deberta-xlarge-mnli\")\n",
    "# # print(results)\n",
    "# precision = sum(results['precision'])/len(results['precision'])\n",
    "# recall = sum(results['recall'])/len(results['recall'])\n",
    "# f1 = sum(results['f1'])/len(results['f1'])\n",
    "\n",
    "# print(precision)\n",
    "# print(recall)\n",
    "# print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [00:14<00:00, 51.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2856, device='cuda:4')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "750it [00:14, 51.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5258, device='cuda:4') 0.37733333333333335\n"
     ]
    }
   ],
   "source": [
    "# ACS\n",
    "cosine_sim_scores = [compute_similarity_between_parts_without_f1(sent) for sent in tqdm(pred_captions)]\n",
    "avg_sim_score = sum(cosine_sim_scores)/len(cosine_sim_scores)\n",
    "print(avg_sim_score)\n",
    "\n",
    "\n",
    "# ACD\n",
    "\n",
    "cosine_scores = [compute_similarity_between_parts(sent, f1_score) for sent,f1_score in tqdm(zip(pred_captions, results['f1']) )]\n",
    "# print(cosine_scores[0:5])\n",
    "avg_score = sum(cosine_scores)/len(cosine_scores)\n",
    "different_statements = [score for score in cosine_scores if score < 0.5]\n",
    "print(avg_score, len(different_statements)/len(pred_captions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_primary_secondary_concepts = [split_to_parts(sent) for sent in tqdm(pred_captions)]\n",
    "# print(primary_secondary_concepts[0:5])\n",
    "pred_primary_concepts = [item[0] for item in pred_primary_secondary_concepts]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "true_primary_secondary_concepts = [split_to_parts(sent) for sent in tqdm(true_captions)]\n",
    "true_primary_concepts = [item[0] for item in true_primary_secondary_concepts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def unique_words(captions):\n",
    "    tokens = []\n",
    "\n",
    "    for caption in captions:\n",
    "        words = nltk.word_tokenize(caption)\n",
    "        tokens += words\n",
    "\n",
    "    print(len(tokens))\n",
    "    print(len(list(set(tokens))) / len(pred_captions))\n",
    "\n",
    "unique_words(pred_primary_concepts)\n",
    "unique_words(true_primary_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_primary_concepts[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_primary_concepts[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
